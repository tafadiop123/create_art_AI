# -*- coding: utf-8 -*-
"""My Creative AI by Moustapha.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w33Q7KtQFyJq9YKAREynT9hVt-nAai09

# TACHE #1: COMPRENDRE L'ÉTAT DU PROBLEME ET LE BUSINESS CASE

![alt text](https://drive.google.com/uc?id=1EW5NEV_lA6qAIpb1ZCzRMyZq9zjo9_Gr)

# CREATIVE AI
- Le **"CREATIVE AI"** est une nouvelle branche de l'intelligence artificielle dans laquelle l'IA peut réaliser de la peinture artistique, peut concevoir des histoires passionnantes et peut composer de la musique.


# - Qu'est-ce-que le **"DEEP DREAM"** ?
- Le DEEP DREAM est l'algorithme d'IA le plus bizarre et le plus effrayant à ce jour !
- Vous vous êtes déjà demandé ce que voit l'AI dans les couches cachées **(hidden layers)** ?
- Le DEEP DREAM est un algorithme de computer vision développé par Alex Mordvintsev à Google.
- L'algorithme marche en créant des effets de rêve.
- Il donne à l'être humain l'impression d'avoir pris une drogue extrêmement puissante !
- Au fur et à mesure que l'image est transmise au réseau de neurones, de plus en plus de caractéristiques bizarres apparaissent.
- Vous rappelez-vous quand vous étiez petit et que vous regardiez les nuages en essayant d'interpréter leurs formes ? 
- DEEP DREAM fait la même chose en renforçant les motifs qu'il voit dans une image donnée sur la base de ce qu'il a été entraîné à voir dans le passé au cours de l'entraînement.
- Si le réseau de neurones est entrainé pour voir les animaux sur les images, il va essayer d'extraire les caractéres d'animaux dans chaque image donnée.


# TACHE #2: IMPORTER LE MODÈLE AVEC LES POIDS PRÉ-ENTRAINÉS
"""

import tensorflow as tf

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random 
import os
import PIL.Image
import cv2
import random
from PIL import Image # Python Image Library (PIL) est une librairie qui ajoute un support pour l'ouverture, la manipulation 
                      # et l'enregistrement de nombreux formats de fichiers image différents

tf.__version__

from google.colab import drive
drive.mount('/content/drive')

# Charger le modèle entrainé "inceptionNet", - for more information on Transfer Learning, check previous case studies -
base_model = tf.keras.applications.InceptionV3(include_top = False, weights = 'imagenet')

"""MINI CHALLENGE #1: 
- How many total parameters exist in inceptionNet V3?
---> Il existe **21,802,784 paramétres totaux.**
- Set include top = True and indicate how many total parameters exist now.
---> Lorsqu'on inclut l'argument **top = True**, on a **23,851,784 de paramétres totaux.**
"""

base_model.summary()

base_model_true = tf.keras.applications.InceptionV3(include_top = True, weights = 'imagenet')
base_model_true.summary()

"""# TACHE #3: Récupérer l'image et la pré-traiter

"""

# Ouvrir la première image
# Source: https://www.pxfuel.com/en/free-photo-xxgfs
img_1 = Image.open("/content/drive/My Drive/Colab Notebooks/Modern Artificial Intelligence Masterclass UDEMY/Art and AI/dataset/sky.jpg")

width, height = img_1.size

# Ouvrir la seconde image
# Source: https://commons.wikimedia.org/wiki/File:Georges_Garen_embrasement_tour_Eiffel.jpg
img_2 = Image.open('/content/drive/My Drive/Colab Notebooks/Modern Artificial Intelligence Masterclass UDEMY/Art and AI/dataset/Monument Renaissance.jpg')

img_2 = img_2.resize((width, height))

# Mélangez les 2 images
image = Image.blend(img_1, img_2, 0.5) # alpha --> The interpolation alpha factor. If alpha is 0.0, a copy of the first image is returned.
# If alpha is 1.0, a copy of the second image is returned. 

# Enregistrer l'image mélangée
image.save("/content/drive/My Drive/Colab Notebooks/Modern Artificial Intelligence Masterclass UDEMY/Art and AI/output/img_0.jpg")

# Charger l'image mélangée
Sample_Image = tf.keras.preprocessing.image.load_img('/content/drive/My Drive/Colab Notebooks/Modern Artificial Intelligence Masterclass UDEMY/Art and AI/output/img_0.jpg')

Sample_Image

# Voir les dimensions de l'image
np.shape(Sample_Image)

# Vérifier le type de l'image
type(Sample_Image)

# Convertir en numpy array
Sample_Image = tf.keras.preprocessing.image.img_to_array(Sample_Image)

# Sample_Image = np.array(Sample_Image)

# Confirmer que l'image est convertie en array Numpy
type(Sample_Image)

# Obtenir le maximum et la valeur minimale
print('min pixel values = {}, max pixel values = {}'.format(Sample_Image.min(), Sample_Image.max()))

# Normaliser l'image d'entrée
Sample_Image = np.array(Sample_Image)/255.0
Sample_Image.shape

# Vérifions les valeurs de l'image normalisée
print('min pixel values = {}, max pixel values = {}'.format(Sample_Image.min(), Sample_Image.max()))

# On ajoute une dimension à l'array
Sample_Image = tf.expand_dims(Sample_Image, axis = 0)

# Vérifions les dimensions du nouveau array
np.shape(Sample_Image)

Sample_Image

"""MINI CHALLENGE #2: 
- Perform the opposite of expand dimension 
- Plot the image
"""

# Faisons le contraire de la méthode "expand_dims"
plt.imshow(np.squeeze(Sample_Image))



"""# TACHE #4: EXECUTER LE MODÈLE PRÉ-ENTRAINÉ ET EXPLORER LES ACTIVATIONS

# NOTES:
- Selectionner un layer et en tentant de maximiser la perte qui correspond aux activations générées par la couche d'intérêt.
- On peut sélectionner n'importe quel layer que l'on choisit, les premières couches générent des caractéristiques comme des rebords et les couches profondes générent des caractéristiques plus complexes comme une face entière, une voiture ou des arbres.
- Le réseau initial **(Inception Network)** comporte plusieurs couches concaténées nommées : **"mixed"**
"""

base_model.summary()

# Maximize the activations of these layers
names = ['mixed3', 'mixed5', 'mixed7']

# names = ['mixed3']
layers = [base_model.get_layer(name).output for name in names]

# Créer le modèle 
deepdream_model = tf.keras.Model(inputs = base_model.input, outputs = layers)

deepdream_model.summary()

# Exécutons le modèle en mettant dans le réseau notre image d'entrée et regarder les activations "Neuron outputs"
activations = deepdream_model(Sample_Image)
activations

len(activations)

"""MINI CHALLENGE #3: 
- Generate the activations for a deeper layer such as 'mixed8' and 'mixed9'.
- What is the size of the generated activations?
- Combine 4 activations from early and deeper layers such as 'mixed3', 'mixed5', 'mixed8', 'mixed9'

"""



"""# TACHE #5: COMPRENDRE COMMENT L'ALGORITHME **"DEEP DREAM"** MARCHE

- Si l'on fournit au CNN une image, le premières layers généralement détecte les caractéristiques basiques comme les bords ou contours.
- Plus tu rentres en profondeur dans le réseau de neurones, plus les caractéristiques complexes sont détectés comme les visages, les arbres et les voitures.



Source #1: https://www.topbots.com/advanced-topics-deep-convolutional-neural-networks/

Source #2: https://wccftech.com/nvidia-demo-skynet-gtc-2014-neural-net-based-machine-learning-intelligence/

- Que se passe t-il lorsque l'on demande à une certaine couche d'accroître ce qu'il détecte sur une image ?
- Que se passe t-il si on demande aux premières couches, qui sont expertes en détection de countours ou rebords, de maximiser ce qu'elles voient ?
- Que se passe t-il si on demande aux dernières couches (les plus profondes), qui sont expertes dans la détection d'éléments (avec des caractéristiques complexes comme les voitures, les visages, etc.), d'accentuer ce qu'elles voient vraiment ?
- Les choses deviennent vraiment rêveur et géniale ! C'est ce que Google appelle **"inceptionism"**.
- **L'inceptionisme** est un phénomène créé par les algorithmes des logiciels de reconnaissance d'image, qui génèrent des images comparables **aux paréidolies**, à partir de photos numériques.
- **Une paréidolie** est un type d’illusion qui fait qu’un stimulus vague ou ambigu est perçu comme clair et distinct par un individu. Autrement dit, tendance instinctive à trouver des formes familières dans des images désordonnées (dans les nuages, les constellations…).
La tendance naturelle qu’a le cerveau humain de percevoir des visages là où il n’y en a pas est un bon exemple de paréidolie.

- Quand on rentre une image dans un **"Artificial Neural Network"**, les neurones s'activent et générent des activations.
- L'algorithme **Deep Dream** marche en essayant de changer les images d'entrées de manière à ce que les neurones s'exicitent plus (accélére l'excitation ou l'activation des neurones). Dés lors, on pourra choisir quelles sont les neurones, contenus dans certaines couches, à choisir afin de les exciter de façon éminente.
- Le processus est continuellment répété jusqu'à ce que l'image d'entrée contient maintenant toutes les caractéristiques dont une couche spécifique recherchait initialement.
- Par exemple : Si une certaine couche était experte en reconnaissance de visages de chien et que l'on fait rentrer l'image d'un ciel bleu, alors l'algorithme Deep Dream va continuellement changer l'image d'entrée et va commencer à créer des images contenant des visages de chien sur le ciel bleu. Le processus continue jusqu'à ce que la couche d'intérêt soit satisfaite des résultats.

## Les Etapes de l'Algorithme **DEEP DREAM**

1. Transmettre une image à travers un CNN, un ANN, un ResNet, etc. 
2. Sélectionner une couche de ton choix ( les premières couches captent le rebords, les couches profondes capturent les dimensions entières comme les visages par exemple).
3. Calculer les activations (résultats) provenant des couches d'intérêts.
4. Calculer le gradient des activations avec le respect de l'image d'entrée.
5. Modifier l'image pour accroître ses activations et ainsi mettre en valeur les motifs vues par le réseau de neurone résultant en une image étrangement hallucinante.
6. Itérer et répéter sur plusieurs échelles.

![alt text](https://drive.google.com/uc?id=1R7_C4r4vy2tqIB5Pi-ltyY2N_WC6jSYF)

# TACHE #6: COMPRENDRE COMMENT EFFECTUER LE CALCUL DU GRADIENT ET L'UTILISATION DE LA FONCTON **"TF.GRADIENTTAPE()"**

- **"tf.GradientTape()"** est utilisé pour enregistrer des opérations pour une différenciation automatique.
- Par example, Supposons qu'on a une fonction y = x^3. 
- Le gradient à x = 2 peut être calculé comme suit: dy_dx (ou dy/dx) = 3 * x^2 = 3 * 2^2 = 12.
"""

x = tf.constant(2.0)

with tf.GradientTape() as g:
  g.watch(x)
  y = x * x * x
dy_dx = g.gradient(y, x) # va trouver numpy=12

dy_dx

"""MINI CHALLENGE #4: 
- Using tf.GradientTape(), calculate the gradient of y = x^4 + x^5 at x = 5
- Verify your answer by manually differentation the equation
"""

x = tf.constant(5.0)

with tf.GradientTape() as g:
  g.watch(x)
  y = (x * x * x * x) + (x * x * x * x * x)  
dy_dx = g.gradient(y, x) 
dy_dx

"""# TASK #7: IMPLEMENT DEEP DREAM ALGORITHM - STEP #1 LOSS CALCULATION

- CREDITS: The DeepDream Code has been adopted from Keras Documentation:
- https://www.tensorflow.org/tutorials/generative/deepdream
"""

# Since the cal_closs function includes expand dimension, let's squeeze the image (reduce_dims)
Sample_Image.shape

Sample_Image = tf.squeeze(Sample_Image, axis = 0)

Sample_Image.shape

def calc_loss(image, model):
# Function used for loss calculations
# It works by feedforwarding the input image through the network and generate activations
# Then obtain the average and sum of those outputs

  img_batch = tf.expand_dims(image, axis=0) # Convert into batch format
  layer_activations = model(img_batch) # Run the model
  print('ACTIVATION VALUES (LAYER OUTPUT) =\n', layer_activations)
  # print('ACTIVATION SHAPE =\n', np.shape(layer_activations))

  losses = [] # accumulator to hold all the losses
  for act in layer_activations:
    loss = tf.math.reduce_mean(act) # calculate mean of each activation 
    losses.append(loss)
  
  print('LOSSES (FROM MULTIPLE ACTIVATION LAYERS) = ', losses)
  print('LOSSES SHAPE (FROM MULTIPLE ACTIVATION LAYERS) = ', np.shape(losses))
  print('SUM OF ALL LOSSES (FROM ALL SELECTED LAYERS)= ', tf.reduce_sum(losses))

  return  tf.reduce_sum(losses) # Calculate sum

loss = calc_loss(tf.Variable(Sample_Image), deepdream_model)

loss # Sum up the losses from both activations

"""MINI CHALLENGE #5: 
- What is the sum of all losses when 'mixed3' layer is the only layer used for activations generation?
"""



"""# TASK #8: IMPLEMENT DEEP DREAM ALGORITHM - STEP #2 (CALCULATE THE GRADIENT)

- In this step, we will rely on the loss that has been calculated in the previous step and calculate the gradient with respect to the given input image and then add it to the input original image. 
- Doing so iteratively will result in feeding images that continiously and increasingly excite the neurons and generate more dreamy like images!
"""

# When you annotate a function with tf.function, the function can be called like any other python defined function. 
# The benefit is that it will be compiled into a graph so it will be much faster and could be executed over TPU/GPU

@tf.function
def deepdream(model, image, step_size):
    with tf.GradientTape() as tape:
      # This needs gradients relative to `img`
      # `GradientTape` only watches `tf.Variable`s by default
      tape.watch(image)
      loss = calc_loss(image, model) # call the function that calculate the loss 

    # Calculate the gradient of the loss with respect to the pixels of the input image.
    # The syntax is as follows: dy_dx = g.gradient(y, x) 
    gradients = tape.gradient(loss, image)

    print('GRADIENTS =\n', gradients)
    print('GRADIENTS SHAPE =\n', np.shape(gradients))

    # tf.math.reduce_std computes the standard deviation of elements across dimensions of a tensor
    gradients /= tf.math.reduce_std(gradients)  

    # In gradient ascent, the "loss" is maximized so that the input image increasingly "excites" the layers.
    # You can update the image by directly adding the gradients (because they're the same shape!)
    image = image + gradients * step_size
    image = tf.clip_by_value(image, -1, 1)

    return loss, image

def run_deep_dream_simple(model, image, steps = 100, step_size = 0.01):
  # Convert from uint8 to the range expected by the model.
  image = tf.keras.applications.inception_v3.preprocess_input(image)

  for step in range(steps):
    loss, image = deepdream(model, image, step_size)
    
    if step % 100 == 0:
      plt.figure(figsize=(12,12))
      plt.imshow(deprocess(image))
      plt.show()
      print ("Step {}, loss {}".format(step, loss))

  # clear_output(wait=True)
  plt.figure(figsize=(12,12))
  plt.imshow(deprocess(image))
  plt.show()

  return deprocess(image)

def deprocess(image):
  image = 255*(image + 1.0)/2.0
  return tf.cast(image, tf.uint8)

Sample_Image.shape

# Let's Load the image again and convert it to Numpy array 
Sample_Image = np.array(tf.keras.preprocessing.image.load_img('/content/drive/My Drive/Colab Notebooks/Modern Artificial Intelligence Masterclass UDEMY/Art and AI/output/img_0.jpg'))
dream_img = run_deep_dream_simple(model = deepdream_model, image = Sample_Image, steps = 4000, step_size = 0.001)

"""# TASK #9: (VIDEO) APPLY DEEPDREAM TO GENERATE A SERIES OF IMAGES"""

image = tf.keras.preprocessing.image.load_img("/content/drive/My Drive/Colab Notebooks/Modern Artificial Intelligence Masterclass UDEMY/Art and AI/output/img_0.jpg")

plt.imshow(image)

# Name of the folder
dream_name = 'mars_eiffel'

# Blended image dimension

x_size = 910 # larger the image longer is going to take to fetch the frames 
y_size = 605

# Define Counters 
created_count = 0
max_count = 50

# This helper function loads an image and returns it as a numpy array of floating points

def load_image(filename):
    image = PIL.Image.open(filename)
    return np.float32(image)

for i in range(0, 50):
    # Make sure to create a new folder entitled 'mars_eiffel' and place img_0 in it
    # Get into the dream directory and look for the number of images and then figure out what is the latest image. Hence this 
    # image we are going to start with and let it dream on and on
     
    if os.path.isfile('/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/{}/img_{}.jpg'.format(dream_name, i+1)):
        print("{} present already, continue fetching the frames...".format(i+1))
        
    else:
        # Call the load image funtion
        img_result = load_image(r'/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/{}/img_{}.jpg'.format(dream_name, i))

    
        # Zoom the image 
        x_zoom = 2 # this indicates how quick the zoom is 
        y_zoom = 1
        
        # Chop off the edges of the image and resize the image back to the original shape. This gives the visual changes of a zoom
        img_result = img_result[0+x_zoom : y_size-y_zoom, 0+y_zoom : x_size-x_zoom]
        img_result = cv2.resize(img_result, (x_size, y_size))
        
        # Adjust the RGB value of the image
        img_result[:, :, 0] += 2  # red
        img_result[:, :, 1] += 2  # green
        img_result[:, :, 2] += 2  # blue
        
        # Deep dream model  
        img_result = run_deep_dream_simple(model = deepdream_model, image = img_result, steps = 500, step_size = 0.001)
        
        # Clip the image, convert the datatype of the array, and then convert to an actual image. 
        img_result = np.clip(img_result, 0.0, 255.0)
        img_result = img_result.astype(np.uint8)
        result = PIL.Image.fromarray(img_result, mode='RGB')
        
        # Save all the frames in the dream location
        result.save(r'/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/{}/img_{}.jpg'.format(dream_name, i+1))
        
        created_count += 1
        if created_count > max_count:
            break

"""# TASK #10: (VIDEO) CREATE A VIDEO FROM ALL THE FRAMES"""

from google.colab import files
uploaded = files.upload()

# Unzip the folder

from zipfile import ZipFile
file_name = "mars_eiffel.zip"

with ZipFile(file_name, 'r') as zip:
  zip.extractall()
  print('Done')

# Path of all the frames

dream_path = 'mars_eiffel'

# Define the codec and create VideoWriter object 
# Download FFmeg 

fourcc = cv2.VideoWriter_fourcc(*'XVID') # FourCC is a 4-byte code used to specify the video codec

out = cv2.VideoWriter('deepdreamvideo.avi', fourcc , 5.0, (910, 605)) # Specify the fourCC, frames per second (fps),
                                                                            # and frame size
# The frames per second value is depends on few important things
# 1. The number of frames we have created. Less number of frames brings small fps
# 2. The larger the image the bigger the fps value. For example, 1080 pixel image can bring 60 fps

for i in range(9999999999999):
    
    # Get into the dream directory and looks for the number of images and then figure out what is the latest image. Hence with 
    # this image we are going to start with and let it dream on and on
    if os.path.isfile('mars_eiffel/img_{}.jpg'.format(i+1)):
        pass
    # Figure out how long the dream is 
    else:
        dream_length = i
        break

dream_length

for i in range(dream_length):
    
    # Build the frames of cv2.VideoWriter
    img_path = os.path.join(dream_path,'img_{}.jpg'.format(i)) # join the dream path
    
    print(img_path) # print the image path 
    
    frame = cv2.imread(img_path)
    out.write(frame)

out.release()

"""# GREAT JOB!

# MINI CHALLENGE SOLUTIONS

MINI CHALLENGE #1: 
- How many total parameters exist in inceptionNet V3?
- Set include top = True and indicate how many total parameters exist now.
"""

Total Params = 23,851,784 (include Top = True)
Total params: 21,802,784 (include Top = False)

"""MINI CHALLENGE #2: """

plt.imshow(np.squeeze(Sample_Image))

"""MINI CHALLENGE #3: 
- Generate the activations for a deeper layer such as 'mixed8' and 'mixed9'.
- What is the size of the generated activations?
- Combine 4 activations from early and deeper layers such as 'mixed3', 'mixed5', 'mixed8', 'mixed9'
"""

names = ['mixed8', 'mixed9']
# shape=(1, 13, 21, 1280)
names = ['mixed3', 'mixed5', 'mixed8', 'mixed9']

"""MINI CHALLENGE #4: 
- Using tf.GradientTape(), calculate the gradient of y = x^4 + x^5 at x = 5
- Verify your answer by manually differentation the equation
"""

x = tf.constant(5.0)
with tf.GradientTape() as g:
  g.watch(x)
  y = (x * x * x * x) + (x * x * x * x * x)
dy_dx = g.gradient(y, x) # Will compute to 12
dy_dx

# 500+3125 = 3625

"""MINI CHALLENGE #5: 
- What is the sum of all losses when 'mixed3' layer is the only layer used for activations generation?
"""

# <tf.Tensor: shape=(), dtype=float32, numpy=0.36584973>